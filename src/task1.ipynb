{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ryanschaefer/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package framenet_v17 to\n",
      "[nltk_data]     /Users/ryanschaefer/nltk_data...\n",
      "[nltk_data]   Package framenet_v17 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import framenet as fn\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"framenet_v17\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 88640 entries, 0 to 88639\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Lexical Unit    88640 non-null  object\n",
      " 1   Frame Count     88640 non-null  int64 \n",
      " 2   Frame           88640 non-null  object\n",
      " 3   Sentence Count  88640 non-null  int64 \n",
      " 4   Sentence        87409 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 3.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frame Count</th>\n",
       "      <th>Sentence Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>88640.000000</td>\n",
       "      <td>88640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.203847</td>\n",
       "      <td>57.749492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.781488</td>\n",
       "      <td>59.231118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>401.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Frame Count  Sentence Count\n",
       "count  88640.000000    88640.000000\n",
       "mean       3.203847       57.749492\n",
       "std        1.781488       59.231118\n",
       "min        2.000000        0.000000\n",
       "25%        2.000000       21.000000\n",
       "50%        2.000000       39.000000\n",
       "75%        4.000000       73.000000\n",
       "max       11.000000      401.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexical Unit</th>\n",
       "      <th>Frame Count</th>\n",
       "      <th>Frame</th>\n",
       "      <th>Sentence Count</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faith.n</td>\n",
       "      <td>2</td>\n",
       "      <td>Religious_belief</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>faith.n</td>\n",
       "      <td>2</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>Legend has it that a local woman climbed the h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>degree.n</td>\n",
       "      <td>3</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>degree.n</td>\n",
       "      <td>3</td>\n",
       "      <td>Quantified_mass</td>\n",
       "      <td>29</td>\n",
       "      <td>Specialist labour or industrial correspondents...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>degree.n</td>\n",
       "      <td>3</td>\n",
       "      <td>Quantified_mass</td>\n",
       "      <td>29</td>\n",
       "      <td>The incremental approach has also been known t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88635</th>\n",
       "      <td>evacuate.v</td>\n",
       "      <td>4</td>\n",
       "      <td>Emptying</td>\n",
       "      <td>6</td>\n",
       "      <td>Some nearby buildings have also been evacuated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88636</th>\n",
       "      <td>evacuate.v</td>\n",
       "      <td>4</td>\n",
       "      <td>Emptying</td>\n",
       "      <td>6</td>\n",
       "      <td>The government of the Maldives has decided to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88637</th>\n",
       "      <td>evacuate.v</td>\n",
       "      <td>4</td>\n",
       "      <td>Emptying</td>\n",
       "      <td>6</td>\n",
       "      <td>Let us assume you wish to evacuate the nightcl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88638</th>\n",
       "      <td>evacuate.v</td>\n",
       "      <td>4</td>\n",
       "      <td>Emptying</td>\n",
       "      <td>6</td>\n",
       "      <td>The fire brigade reappeared , bringing them so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88639</th>\n",
       "      <td>evacuate.v</td>\n",
       "      <td>4</td>\n",
       "      <td>Emptying</td>\n",
       "      <td>6</td>\n",
       "      <td>Dense black smoke billowed 3,000ft into the ai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88640 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Lexical Unit  Frame Count             Frame  Sentence Count  \\\n",
       "0          faith.n            2  Religious_belief               0   \n",
       "1          faith.n            2             Trust               1   \n",
       "2         degree.n            3          Quantity               0   \n",
       "3         degree.n            3   Quantified_mass              29   \n",
       "4         degree.n            3   Quantified_mass              29   \n",
       "...            ...          ...               ...             ...   \n",
       "88635   evacuate.v            4          Emptying               6   \n",
       "88636   evacuate.v            4          Emptying               6   \n",
       "88637   evacuate.v            4          Emptying               6   \n",
       "88638   evacuate.v            4          Emptying               6   \n",
       "88639   evacuate.v            4          Emptying               6   \n",
       "\n",
       "                                                Sentence  \n",
       "0                                                    NaN  \n",
       "1      Legend has it that a local woman climbed the h...  \n",
       "2                                                    NaN  \n",
       "3      Specialist labour or industrial correspondents...  \n",
       "4      The incremental approach has also been known t...  \n",
       "...                                                  ...  \n",
       "88635  Some nearby buildings have also been evacuated...  \n",
       "88636  The government of the Maldives has decided to ...  \n",
       "88637  Let us assume you wish to evacuate the nightcl...  \n",
       "88638  The fire brigade reappeared , bringing them so...  \n",
       "88639  Dense black smoke billowed 3,000ft into the ai...  \n",
       "\n",
       "[88640 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../datasets/lexical_unit_sentences.csv\")\n",
    "\n",
    "display(df.info())\n",
    "display(df.describe())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lexical Unit\n",
       "if.scon    201\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Lexical Unit\"].str.contains(\"if\\.\")][\"Lexical Unit\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lexical Unit\n",
       "v       1092\n",
       "n        614\n",
       "a        235\n",
       "prep      27\n",
       "adv       17\n",
       "scon       1\n",
       "c          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Lexical Unit\"].drop_duplicates().str.split(\".\").apply(lambda x: x[1]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifyLexicalUnits:\n",
    "    def __init__(\n",
    "        self, pretrained = True, \n",
    "        training_filename = \"../datasets/lexical_unit_sentences.csv\",\n",
    "        model_directory = \"../models/lexical_units\"\n",
    "    ):\n",
    "        self.df = None\n",
    "        self.models = None\n",
    "        self.load_framenet()\n",
    "        if pretrained:\n",
    "            # self.load_training_data(training_filename)\n",
    "            self.load_trained_models(model_directory)\n",
    "            \n",
    "    def load_framenet(self):\n",
    "        nltk.download(\"framenet_v17\")\n",
    "        lexical_units = fn.lus()\n",
    "        lu_names = list(set(map(lambda x: x.name, lexical_units)))\n",
    "        self.lu_frames = { key: [] for key in lu_names }\n",
    "        for lu in lexical_units:\n",
    "            if lu.frame.name not in self.lu_frames[lu.name]:\n",
    "                self.lu_frames[lu.name].append(lu.frame.name)\n",
    "    \n",
    "    def load_training_data(self, filename = \"../datasets/lexical_unit_sentences.csv\"):\n",
    "        self.df = pd.read_csv(filename)\n",
    "        self.df[\"POS\"] = self.df[\"Sentence\"].apply(self.pos_tag)\n",
    "        \n",
    "    def load_trained_models(self, directory = \"../models/lexical_units\"):\n",
    "        self.models = {}\n",
    "        for filename in os.listdir(directory):\n",
    "            comps = filename.split(\".\")\n",
    "            if comps[1] == \"pkl\":\n",
    "                self.models[comps[0]] = pkl.load(open(os.join(directory, filename), \"rb\"))\n",
    "                \n",
    "    def pos_tag(self, sentence):\n",
    "        if type(sentence) != str:\n",
    "            return []\n",
    "        else:\n",
    "            tokens = nltk.word_tokenize(sentence)\n",
    "            base_tags = nltk.pos_tag(tokens)\n",
    "            final_tags = []\n",
    "            for word, tag in base_tags:\n",
    "                if tag.startswith(\"N\"):\n",
    "                    final_tags.append((word, \".n\"))\n",
    "                elif tag.startswith(\"J\"):\n",
    "                    final_tags.append((word, \".a\"))\n",
    "                elif tag.startswith(\"V\"):\n",
    "                    final_tags.append((word, \".v\"))\n",
    "                elif tag.startswith(\"R\"):\n",
    "                    final_tags.append((word, \".adv\"))\n",
    "                elif tag == \"IN\":\n",
    "                    final_tags.append((word, \".prep\"))\n",
    "                elif tag == \"CD\":\n",
    "                    final_tags.append((word, \".num\"))\n",
    "                elif tag == \"CC\":\n",
    "                    final_tags.append((word, \".c\"))\n",
    "                elif tag == \"UH\":\n",
    "                    final_tags.append((word, \".intj\"))\n",
    "                elif tag == \"DT\":\n",
    "                    final_tags.append((word, \".art\"))\n",
    "                else:\n",
    "                    final_tags.append((word, \".scon\"))\n",
    "                    \n",
    "            return final_tags\n",
    "            \n",
    "        \n",
    "    def get_word_lu(self, word, pos):\n",
    "        possible_lus = list(filter(lambda x: x.startswith(\"{}\".format(word.lower())), self.lu_frames.keys()))\n",
    "        if len(possible_lus) == 0:\n",
    "            return None\n",
    "        elif len(possible_lus) == 1:\n",
    "            return possible_lus[0]\n",
    "        else:\n",
    "            tmp = word + pos\n",
    "            if tmp in possible_lus:\n",
    "                return tmp\n",
    "            else:\n",
    "                return None\n",
    "            \n",
    "    def process_sentence(self, sentence):\n",
    "        pass\n",
    "    \n",
    "    def predict_frame(self, lu, sentence):\n",
    "        features = self.process_sentence(sentence)\n",
    "        return self.models[lu].predict(features)\n",
    "    \n",
    "    def fit(self, df_train = None, output_dir = \"../models/lexical_units\"):\n",
    "        if df_train is not None:\n",
    "            self.df = copy.deepcopy(df_train)\n",
    "            self.df[\"POS\"] = self.df[\"Sentence\"].apply(self.pos_tag)\n",
    "    \n",
    "    def predict(self, sentences, model_dir = None):\n",
    "        if self.models is None:\n",
    "            if model_dir is None:\n",
    "                self.load_trained_models()\n",
    "            else:\n",
    "                self.load_trained_models(model_dir)\n",
    "                \n",
    "        pos = list(map(self.pos_tag, sentences))\n",
    "        predictions = []\n",
    "        for i in range(len(sentences)):\n",
    "            curr = []\n",
    "            for word, tag in pos[i]:\n",
    "                lu = self.get_word_lu(word, tag)\n",
    "                if lu is not None:\n",
    "                    possible_frames = self.lu_frames[lu]\n",
    "                    if len(possible_frames) == 1:\n",
    "                        curr.append(possible_frames[0])\n",
    "                    # else:\n",
    "                    #     curr.append(self.predict_frame(lu, sentences[i]))\n",
    "            predictions.append(curr)\n",
    "            \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package framenet_v17 to\n",
      "[nltk_data]     /Users/ryanschaefer/nltk_data...\n",
      "[nltk_data]   Package framenet_v17 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "clu = ClassifyLexicalUnits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Fame',\n",
       "  'Degree',\n",
       "  'Political_locales',\n",
       "  'People',\n",
       "  'Natural_features',\n",
       "  'Personal_relationship',\n",
       "  'Distributed_position',\n",
       "  'Natural_features',\n",
       "  'Cardinal_numbers',\n",
       "  'Personal_relationship',\n",
       "  'Biological_urge',\n",
       "  'Performers_and_roles',\n",
       "  'Representing',\n",
       "  'Duration_description']]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clu.predict([df[\"Sentence\"][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n       4694\n",
       "v       3318\n",
       "a       2042\n",
       "adv      220\n",
       "prep      99\n",
       "num       31\n",
       "idio      29\n",
       "scon      12\n",
       "art        6\n",
       "c          5\n",
       "intj       5\n",
       "pron       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series.value_counts(list(map(lambda x: x.split(\".\")[1], clu.lu_frames.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['much.art', 'most.art', 'some.art', 'a few.art', 'little.art', 'no.art']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: x.endswith(\".art\"), clu.lu_frames.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
