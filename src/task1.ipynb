{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import framenet as fn\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 88640 entries, 0 to 88639\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Lexical Unit    88640 non-null  object\n",
      " 1   Frame Count     88640 non-null  int64 \n",
      " 2   Frame           88640 non-null  object\n",
      " 3   Sentence Count  88640 non-null  int64 \n",
      " 4   Sentence        87409 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 3.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Frame Count</th>\n",
       "      <th>Sentence Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>88640.000000</td>\n",
       "      <td>88640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.203847</td>\n",
       "      <td>57.749492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.781488</td>\n",
       "      <td>59.231118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>73.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>401.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Frame Count  Sentence Count\n",
       "count  88640.000000    88640.000000\n",
       "mean       3.203847       57.749492\n",
       "std        1.781488       59.231118\n",
       "min        2.000000        0.000000\n",
       "25%        2.000000       21.000000\n",
       "50%        2.000000       39.000000\n",
       "75%        4.000000       73.000000\n",
       "max       11.000000      401.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lexical Unit</th>\n",
       "      <th>Frame Count</th>\n",
       "      <th>Frame</th>\n",
       "      <th>Sentence Count</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faith.n</td>\n",
       "      <td>2</td>\n",
       "      <td>Religious_belief</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>faith.n</td>\n",
       "      <td>2</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>Legend has it that a local woman climbed the h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>degree.n</td>\n",
       "      <td>3</td>\n",
       "      <td>Quantity</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>degree.n</td>\n",
       "      <td>3</td>\n",
       "      <td>Quantified_mass</td>\n",
       "      <td>29</td>\n",
       "      <td>Specialist labour or industrial correspondents...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>degree.n</td>\n",
       "      <td>3</td>\n",
       "      <td>Quantified_mass</td>\n",
       "      <td>29</td>\n",
       "      <td>The incremental approach has also been known t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88635</th>\n",
       "      <td>evacuate.v</td>\n",
       "      <td>4</td>\n",
       "      <td>Emptying</td>\n",
       "      <td>6</td>\n",
       "      <td>Some nearby buildings have also been evacuated...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88636</th>\n",
       "      <td>evacuate.v</td>\n",
       "      <td>4</td>\n",
       "      <td>Emptying</td>\n",
       "      <td>6</td>\n",
       "      <td>The government of the Maldives has decided to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88637</th>\n",
       "      <td>evacuate.v</td>\n",
       "      <td>4</td>\n",
       "      <td>Emptying</td>\n",
       "      <td>6</td>\n",
       "      <td>Let us assume you wish to evacuate the nightcl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88638</th>\n",
       "      <td>evacuate.v</td>\n",
       "      <td>4</td>\n",
       "      <td>Emptying</td>\n",
       "      <td>6</td>\n",
       "      <td>The fire brigade reappeared , bringing them so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88639</th>\n",
       "      <td>evacuate.v</td>\n",
       "      <td>4</td>\n",
       "      <td>Emptying</td>\n",
       "      <td>6</td>\n",
       "      <td>Dense black smoke billowed 3,000ft into the ai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88640 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Lexical Unit  Frame Count             Frame  Sentence Count  \\\n",
       "0          faith.n            2  Religious_belief               0   \n",
       "1          faith.n            2             Trust               1   \n",
       "2         degree.n            3          Quantity               0   \n",
       "3         degree.n            3   Quantified_mass              29   \n",
       "4         degree.n            3   Quantified_mass              29   \n",
       "...            ...          ...               ...             ...   \n",
       "88635   evacuate.v            4          Emptying               6   \n",
       "88636   evacuate.v            4          Emptying               6   \n",
       "88637   evacuate.v            4          Emptying               6   \n",
       "88638   evacuate.v            4          Emptying               6   \n",
       "88639   evacuate.v            4          Emptying               6   \n",
       "\n",
       "                                                Sentence  \n",
       "0                                                    NaN  \n",
       "1      Legend has it that a local woman climbed the h...  \n",
       "2                                                    NaN  \n",
       "3      Specialist labour or industrial correspondents...  \n",
       "4      The incremental approach has also been known t...  \n",
       "...                                                  ...  \n",
       "88635  Some nearby buildings have also been evacuated...  \n",
       "88636  The government of the Maldives has decided to ...  \n",
       "88637  Let us assume you wish to evacuate the nightcl...  \n",
       "88638  The fire brigade reappeared , bringing them so...  \n",
       "88639  Dense black smoke billowed 3,000ft into the ai...  \n",
       "\n",
       "[88640 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../datasets/lexical_unit_sentences.csv\")\n",
    "\n",
    "display(df.info())\n",
    "display(df.describe())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifyLexicalUnits:\n",
    "    def __init__(\n",
    "        self, load_training = True, pretrained = True, \n",
    "        training_filename = \"../datasets/lexical_unit_sentences.csv\",\n",
    "        model_directory = \"../models/lexical_units\"\n",
    "    ):\n",
    "        self.df = None\n",
    "        self.models = None\n",
    "        self.rules = None\n",
    "        self.load_framenet()\n",
    "    \n",
    "        if load_training:\n",
    "            self.load_training_data(training_filename)\n",
    "            \n",
    "        if pretrained:\n",
    "            self.load_trained_models(model_directory)\n",
    "            \n",
    "    def load_framenet(self):\n",
    "        nltk.download(\"framenet_v17\")\n",
    "        lexical_units = fn.lus()\n",
    "        lu_names = list(set(map(lambda x: x.name.replace(\".\", \"_\"), lexical_units)))\n",
    "        self.lu_frames = { key: [] for key in lu_names }\n",
    "        for lu in lexical_units:\n",
    "            name = str.replace(lu.name, \".\", \"_\")\n",
    "            if name not in self.lu_frames[name]:\n",
    "                self.lu_frames[name].append(lu.frame.name)\n",
    "                self.lu_frames[name] = list(sorted(self.lu_frames[name]))\n",
    "    \n",
    "    def load_training_data(self, filename = \"../datasets/lexical_unit_sentences.csv\"):\n",
    "        self.df = pd.read_csv(filename)\n",
    "        self.df[\"POS\"] = self.df[\"Sentence\"].apply(self.pos_tag)\n",
    "        self.df[\"Lexical Unit\"] = self.df[\"Lexical Unit\"].str.replace(\".\", \"_\")\n",
    "        \n",
    "    def load_trained_models(self, directory = \"../models/lexical_units\"):\n",
    "        self.models = {}\n",
    "        self.rules = json.load(open(\"{}/rules.json\".format(directory)))\n",
    "        for filename in os.listdir(directory):\n",
    "            comps = filename.split(\".\")\n",
    "            if comps[1] == \"pkl\":\n",
    "                self.models[comps[0]] = pkl.load(open(os.join(directory, filename), \"rb\"))\n",
    "                \n",
    "    def pos_tag(self, sentence):\n",
    "        if type(sentence) != str:\n",
    "            return []\n",
    "        else:\n",
    "            tokens = nltk.word_tokenize(sentence)\n",
    "            base_tags = nltk.pos_tag(tokens)\n",
    "            final_tags = []\n",
    "            for word, tag in base_tags:\n",
    "                if tag.startswith(\"N\"):\n",
    "                    final_tags.append((word, \"_n\"))\n",
    "                elif tag.startswith(\"J\"):\n",
    "                    final_tags.append((word, \"_a\"))\n",
    "                elif tag.startswith(\"V\"):\n",
    "                    final_tags.append((word, \"_v\"))\n",
    "                elif tag.startswith(\"R\"):\n",
    "                    final_tags.append((word, \"_adv\"))\n",
    "                elif tag == \"IN\":\n",
    "                    final_tags.append((word, \"_prep\"))\n",
    "                elif tag == \"CD\":\n",
    "                    final_tags.append((word, \"_num\"))\n",
    "                elif tag == \"CC\":\n",
    "                    final_tags.append((word, \"_c\"))\n",
    "                elif tag == \"UH\":\n",
    "                    final_tags.append((word, \"_intj\"))\n",
    "                elif tag == \"DT\":\n",
    "                    final_tags.append((word, \"_art\"))\n",
    "                else:\n",
    "                    final_tags.append((word, \"_scon\"))\n",
    "                    \n",
    "            return final_tags\n",
    "            \n",
    "        \n",
    "    def get_word_lu(self, word, pos):\n",
    "        possible_lus = list(filter(lambda x: x.startswith(\"{}\".format(word.lower())), self.lu_frames.keys()))\n",
    "        if len(possible_lus) == 0:\n",
    "            return None\n",
    "        elif len(possible_lus) == 1:\n",
    "            return possible_lus[0]\n",
    "        else:\n",
    "            tmp = word + pos\n",
    "            if tmp in possible_lus:\n",
    "                return tmp\n",
    "            else:\n",
    "                return None\n",
    "            \n",
    "    def process_sentence(self, sentence):\n",
    "        # presence/absence of words\n",
    "        # use parse tree (what does structure look like)\n",
    "        # spacy has a dependency parser <-\n",
    "        # look at children edge labels of children in dependency tree\n",
    "        # surrounding words\n",
    "        # word count\n",
    "        # where lu is relative to sentence length <-\n",
    "        # bool vars for certain words being present\n",
    "        # lexical parse tree\n",
    "        # named entities\n",
    "        # POS counts\n",
    "        return np.array([])\n",
    "    \n",
    "    def predict_frame(self, lu, sentence):\n",
    "        if lu in self.rules.keys():\n",
    "            probs = self.rules[lu]\n",
    "            pred_frame = np.random.choice(list(probs.keys()), p = list(probs.values()))\n",
    "            return pred_frame\n",
    "        elif lu in self.models.keys():\n",
    "            features = [self.process_sentence(sentence)]\n",
    "            return None\n",
    "            return self.models[lu].predict(features)[0]\n",
    "        else:\n",
    "            raise Exception(\"Unknown lexical unit: {}\".format(lu))\n",
    "    \n",
    "    def fit(self, df_train = None, output_dir = \"../models/lexical_units\", random_state = None):\n",
    "        if df_train is not None:\n",
    "            self.df = copy.deepcopy(df_train)\n",
    "            self.df[\"POS\"] = self.df[\"Sentence\"].apply(self.pos_tag)\n",
    "        elif self.df is None:\n",
    "            self.load_training_data()\n",
    "            \n",
    "        self.rules = {}\n",
    "        self.models = {}\n",
    "        for lu, frames in self.lu_frames.items():\n",
    "            if len(frames) > 1:\n",
    "                df_lu = self.df[self.df[\"Lexical Unit\"] == lu]\n",
    "                frame_counts = df_lu.groupby(\"Frame\")[\"Sentence\"].count()\n",
    "                if min(frame_counts) < 10:\n",
    "                    frame_counts = frame_counts / sum(frame_counts)\n",
    "                    self.rules[lu] = frame_counts.to_dict()\n",
    "                else:\n",
    "                    features = df_lu[\"Sentence\"].apply(self.process_sentence).to_numpy()\n",
    "                    # model = DecisionTreeClassifier(random_state = random_state)\n",
    "                    # model.fit(features, df_lu[\"Frame\"])\n",
    "                    # pkl.dump(model, open(\"{}/{}.pkl\".format(output_dir, lu), \"wb\"))\n",
    "                    # self.models[lu] = model\n",
    "                    \n",
    "        json.dump(self.rules, open(\"{}/rules.json\".format(output_dir), \"w\"), indent = 4)\n",
    "    \n",
    "    def predict(self, sentences, model_dir = None):\n",
    "        if self.models is None:\n",
    "            if model_dir is None:\n",
    "                self.load_trained_models()\n",
    "            else:\n",
    "                self.load_trained_models(model_dir)\n",
    "                \n",
    "        pos = list(map(self.pos_tag, sentences))\n",
    "        predictions = []\n",
    "        for i in range(len(sentences)):\n",
    "            curr = []\n",
    "            for word, tag in pos[i]:\n",
    "                lu = self.get_word_lu(word, tag)\n",
    "                if lu is not None:\n",
    "                    possible_frames = self.lu_frames[lu]\n",
    "                    if len(possible_frames) == 1:\n",
    "                        curr.append((lu, possible_frames[0]))\n",
    "                    else:\n",
    "                        curr.append((lu, self.predict_frame(lu, sentences[i])))\n",
    "            predictions.append(curr)\n",
    "            \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package framenet_v17 to\n",
      "[nltk_data]     /Users/ryanschaefer/nltk_data...\n",
      "[nltk_data]   Package framenet_v17 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "clu = ClassifyLexicalUnits(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "large = clu.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legend has it that a local woman climbed the hill every day to watch for her husband returning from across the sea ; one day the wife and her child were turned to stone as a permanent symbol of her enduring faith .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('legendary_a', 'Fame'),\n",
       " ('that_adv', 'Degree'),\n",
       " ('local_a', 'Political_locales'),\n",
       " ('woman_n', 'People'),\n",
       " ('hill_n', 'Natural_features'),\n",
       " ('day_n', 'Calendric_unit'),\n",
       " ('watch_v', 'Perception_active'),\n",
       " ('for_prep', 'Taking_sides'),\n",
       " ('husband_n', 'Personal_relationship'),\n",
       " ('from_prep', 'Origin'),\n",
       " ('across_prep', 'Distributed_position'),\n",
       " ('sea_n', 'Natural_features'),\n",
       " ('one_num', 'Cardinal_numbers'),\n",
       " ('day_n', 'Calendric_unit'),\n",
       " ('wife_n', 'Personal_relationship'),\n",
       " ('child_n', 'People_by_age'),\n",
       " ('turned on_a', 'Biological_urge'),\n",
       " ('stone_v', 'Cause_harm'),\n",
       " ('as_prep', 'Performers_and_roles'),\n",
       " ('symbolize_v', 'Representing'),\n",
       " ('of_prep', 'Partitive'),\n",
       " ('enduring_a', 'Duration_description'),\n",
       " ('faith_n', 'Trust')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = [df[\"Sentence\"][1]]\n",
    "predicted_frames = clu.predict(sentences)\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    print(sentences[i])\n",
    "    display(predicted_frames[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
